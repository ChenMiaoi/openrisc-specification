[[MemoryManagement]]
:imagesdir: {docdir}/../assets/images
:codedir: {docdir}/../assets/resource/code

== Memory Management

This chapter describes the virtual memory and access protection mechanisms for memory management within the OpenRISC 1000 architecture.

Note that this chapter describes the address translation mechanism from the perspective of the programming model. As such, it describes the structure of the page tables, the MMU conditions that cause MMU related exceptions and the MMU registers. The hardware implementation details that are invisible to the OpenRISC 1000 programming model, such as MMU organization and TLB size, are not contained in the architectural definition.

=== MMU Features

The OpenRISC 1000 memory management unit includes the following principal features:

* Support for effective address (EA) of 32 bits and 64 bits
* Support for implementation specific size of physical address spaces up to 35 address bits (32 GByte)
* Three different page sizes:
* Level 0 pages (32 Gbyte; only with 64-bit EA) translated with D/I Area Translation Buffer (ATB)
* Level 1 pages (16 MByte) translated with D/I Area Translation Buffer (ATB)
* Level 2 pages (8 Kbyte) translated with D/I Translation Lookaside Buffer (TLB)
* Address translation using one-, two- or three-level page tables
* Powerful page based access protection with support for demand-paged virtual memory
* Support for simultaneous multi-threading (SMT)

=== MMU Overview

The primary functions of the MMU in an OpenRISC 1000 processor are to translate effective addresses to physical addresses for memory accesses. In addition, the MMU provides various levels of access protection on a page-by-page basis. Note that this chapter describes the conceptual model of the OpenRISC 1000 MMU and implementations may differ in the specific hardware used to implement this model.

Two general types of accesses generated by OpenRISC 1000 processors require address translation - instruction accesses generated by the instruction fetch unit, and data accesses generated by the load and store unit. Generally, the address translation mechanism is defined in terms of page tables used by OpenRISC 1000 processors to locate the effective to physical address mapping for instruction and data accesses.

The definition of page table data structures provides significant flexibility for the implementation of performance enhancement features in a wide range of processors. 

Therefore, the performance enhancements used to the page table information on-chip vary from implementation to implementation.

Translation lookaside buffers (TLBs) are commonly implemented in OpenRISC 1000 processors to keep recently-used page address translations on-chip. Although their exact implementation is not specified, the general concepts that are pertinent to the system software are described.

image::{imagesdir}/png/figure8-1.png

Large areas can be translated with optional facility called Area Translation Buffer (ATB). ATBs translate 16MB and 32GB pages. If xTLB and xATB have a match on the same virtual address, xTLB is used.

The MMU, together with the exception processing mechanism, provides the necessary support for the operating system to implement a paged virtual memory environment and for enforcing protection of designated memory areas.

=== MMU Exceptions

To complete any memory access, the effective address must be translated to a physical address. An MMU exception occurs if this translation fails.

TLB miss exceptions can happen only on OpenRISC 1000 processor implementations that do TLB reload in software.

The page fault exceptions that are caused by missing PTE in page table or page access protection can happen on any OpenRISC 1000 processor implementations.

[[MMUExceptions]]
.MMU Exceptions
[%autowidth, float="center", align="center", cols="^,^,^", options="headers",]
|===
|*EXCEPTION NAME*	|*VECTOR OFFSET*	|*CAUSING CONDITIONS*
|Data Page Fault	|0x300	|No matching PTE found in page tables or page protection violation for load/store operations.
|Instruction Page Fault	|0x400	|No matching PTE found in page tables or page protection violation for instruction fetch.
|DTLB Miss	|0x900	|No matching entry in DTLB.
|ITLB Miss	|0xA00	|No matching entry in ITLB.
|===

The vector offset addresses in table are subject to the presence and setting of the of the Exception Vector Base Address Register (EVBAR) may have configured the exceptions to be processed at a different offset, however the least-significant 12-bit offset address remain the same.

The state saved by the processor for each of the exceptions in Table 9-2 contains information that identifies the address of the failing instruction. Refer to the chapter entitled “Exception Processing” on page 273 for a more detailed description of exception processing.

=== MMU Special-Purpose Registers

Table 8-2 summarizes the registers that the operating system uses to program the MMU. These registers are 32-bit special-purpose supervisor-level registers accessible with the l.mtspr/l.mfspr instructions in supervisor mode only.

Table 8-2 does not show two configuration registers that are implemented if implementation implements configuration registers. DMMUCFGR and IMMUCFGR describe capability of DMMU and IMMU.

[[MMUSpecialPurposeRegisters]]
.List of MMU Special-Purpose Registers
[%autowidth, float="center", align="center", cols="^,^,^,^,^,^", options="headers",]
|===
|*Grp #*	|*Reg #*	|*Reg Name*	|*USER MODE*	|*SUPV MODE*	|*Description*
|1	|0	|DMMUCR	|–	|R/W	|Data MMU Control register
|1	|1	|DMMUPR	|–	|R/W	|Data MMU Protection Register
|1	|2	|DTLBEIR	|–	|W	|Data TLB Entry Invalidate register
|1	|4-7	|DATBMR0-DATBMR3	|–	|R/W	|Data ATB Match registers
|1	|8-11	|DATBTR0-DATBTR3	|–	|R/W	|Data ATB Translate registers
|1	|512-639	|DTLBW0MR0-DTLBW0MR127	|–	|R/W	|Data TLB Match registers Way 0
|1	|640-767	|DTLBW0TR0-DTLBW0TR127	|–	|R/W	|Data TLB Translate registers Way 0
|1	|768-895	|DTLBW1MR0-DTLBW1MR127	|–	|R/W	|Data TLB Match registers Way 1
|1	|896-1023	|DTLBW1TR0-DTLBW1TR127	|–	|R/W	|Data TLB Translate registers Way 1
|1	|1024-1151	|DTLBW2MR0-DTLBW2MR127	|–	|R/W	|Data TLB Match registers Way 2
|1	|1152-1279	|DTLBW2TR0-DTLBW2TR127	|–	|R/W	|Data TLB Translate registers Way 2
|1	|1280-1407	|DTLBW3MR0-DTLBW3MR127	|–	|R/W	|Data TLB Match registers Way 3
|1	|1408-1535	|DTLBW3TR0-DTLBW3TR127	|–	|R/W	|Data TLB Translate registers Way 3
|2	|0	|IMMUCR	|–	|R/W	|Instruction MMU Control register
|2	|1	|IMMUPR	|–	|R/W	|Instruction MMU Protection Register
|2	|2	|ITLBEIR	|–	|W	|Instruction TLB Entry Invalidate register
|2	|4-7	|IATBMR0-IATBMR3	|–	|R/W	|Instruction ATB Match registers
|2	|8-11	|IATBTR0-IATBTR3	|–	|R/W	|Instruction ATB Translate registers
|2	|512-639	|ITLBW0MR0-ITLBW0MR127	|–	|R/W	|Instruction TLB Match registers Way 0
|2	|640-767	|ITLBW0TR0-ITLBW0TR127	|–	|R/W	|Instruction TLB Translate registers Way 0
|2	|768-895	|ITLBW1MR0-ITLBW1MR127	|–	|R/W	|Instruction TLB Match registers Way 1
|2	|896-1023	|ITLBW1TR0-ITLBW1TR127	|–	|R/W	|Instruction TLB Translate registers Way 1
|2	|1024-1151	|ITLBW2MR0-ITLBW2MR127	|–	|R/W	|Instruction TLB Match registers Way 2
|2	|1152-1279	|ITLBW2TR0-ITLBW2TR127	|–	|R/W	|Instruction TLB Translate registers Way 2
|2	|1280-1407	|ITLBW3MR0-ITLBW3MR127	|–	|R/W	|Instruction TLB Match registers Way 3
|2	|1408-1535	|ITLBW3TR0-ITLBW3TR127	|–	|R/W	|Instruction TLB Translate registers Way 3
|===

As TLBs are noncoherent caches of PTEs, software that changes the page tables in any way must perform the appropriate TLB invalidate operations to keep the on-chip TLBs coherent with respect to the page tables in memory.

==== Data MMU Control Register(DMMUCR)

The DMMUCR is a 32-bit special-purpose supervisor-level register accessible with the l.mtspr/l.mfspr instructions in supervisor mode.

It provides general control of the DMMU.

include::{imagesdir}/wavedrom/edn/dmmucr.edn[]

[[DMMUCR]]
.DMMUCR Field Descriptions
[%autowidth, float="center", align="center", cols="^,^", options="headers",]
|===
|DTF	|DTLB Flush +
0 DTLB ready for operation +
1 DTLB flush request/status
|PTBP	|Page Table Base Pointer +
N 22-bit pointer to the base of page directory/table 
|===

The PTBP field in the DMMUCR is required only in implementations with hardware PTE reload support. Implementations that use software TLB reload are not required to implement this field because the page table base pointer is stored in a TLB miss exception handler’s variable.

The DTF is optional and when implemented it flushes entire DTLB.

==== Data MMU Protection Register(DMMUPR)

The DMMUPR is a 32-bit special-purpose supervisor-level register accessible with the l.mtspr/l.mfspr instructions in supervisor mode.

It defines 7 protection groups indexed by PPI fields in PTEs.

include::{imagesdir}/wavedrom/edn/dmmupr.edn[]

[[DMMUPR]]
.DMMUPR Field Descriptions
[%autowidth, float="center", align="center", cols="^,^", options="headers",]
|===
|SREx	|Supervisor Read Enable x +
0 Load operation in supervisor mode not permitted +
1 Load operation in supervisor mode permitted

|SWEx	|Supervisor Write Enable x +
0 Store operation in supervisor mode not permitted +
1 Store operation in supervisor mode permitted

|UREx	|User Read Enable x +
0 Load operation in user mode not permitted +
1 Load operation in user mode permitted

|UWEx	|User Write Enable x +
0 Store operation in user mode not permitted +
1 Store operation in user mode permitted
|===

A DMMUPR is required only in implementations with hardware PTE reload support. Implementations that use software TLB reload are not required to implement this register; instead a TLB miss handler should have a software variable as replacement for the DMMUPR and it should do a software look-up operation and set DTLBWyTRx protection bits accordingly.

==== Instruction MMU Control Register(IMMUCR)

The IMMUCR is a 32-bit special-purpose supervisor-level register accessible with the l.mtspr/l.mfspr instructions in supervisor mode.

It provides general control of the IMMU.

include::{imagesdir}/wavedrom/edn/immucr.edn[]

[[IMMUCR]]
.IMMUCR Field Descriptions
[%autowidth, float="center", align="center", cols="^,^", options="headers",]
|===
|ITF	|ITLB Flush +
0 ITLB ready for operation +
1 ITLB flush request/status
|PTBP	|Page Table Base Pointer +
N 22-bit pointer to the base of page directory/table 
|===

The PTBP field in xMMUCR is required only in implementations with hardware PTE reload support. Implementations that use software TLB reload are not required to implement this field because the page table base pointer is stored in a TLB miss exception handler’s variable.

The ITF is optional and when implemented it flushes entire ITLB.

==== Instruction MMU Protection Register(IMMUPR)

The IMMUP register is a 32-bit special-purpose supervisor-level register accessible with the l.mtspr/l.mfspr instructions in supervisor mode.

It defines 7 protection groups indexed by PPI fields in PTEs.

include::{imagesdir}/wavedrom/edn/immupr.edn[]

[[IMMUPR]]
.IMMUPR Field Descriptions
[%autowidth, float="center", align="center", cols="^,^", options="headers",]
|===
|SXEx	|Supervisor Execute Enable x +
0 Instruction fetch in supervisor mode not permitted +
1 Instruction fetch in supervisor mode permitted
|UXEx	|User Execute Enable x +
0 Instruction fetch in user mode not permitted +
1 Instruction fetch in user mode permitted
|===

The IMMUPR is required only in implementations with hardware PTE reload support. Implementations that use software TLB reload are not required to implement this register; instead the TLB miss handler should have a software variable as replacement for the IMMUPR register and it should do a software look-up operation and set ITLBWyTRx protection bits accordingly.

==== Instruction/Data TLB Entry Invalidata Registers(xTLBEIR)

The instruction/data TLB entry invalidate registers are special-purpose registers accessible with the l.mtspr/l.mfspr instructions in supervisor mode. They are 32 bits wide in 32-bit implementations and 64 bits wide in 64-bit implementation.

The xTLBEIR is written with the effective address. The corresponding xTLB entry is invalidated in the local processor.

include::{imagesdir}/wavedrom/edn/xtlbeir.edn[]

[[XTLBEIR]]
.XTLBEIR Field Descriptions
[%autowidth, float="center", align="center", cols="^,^", options="headers",]
|===
|EA	|Effective Address +
EA that targets TLB entry inside TLB
|===

==== Instruction/Data Translation Lookaside Buffer Way Match Registers(xTLBWyMR0-xTLBWyMR127)

The xTLBWyMR registers are 32-bit special-purpose supervisor-level registers accessible with the l.mtspr/l.mfspr instructions in supervisor mode.

Together with the xTLBWyTR registers they cache translation entries used for translating virtual to physical address. A virtual address is formed from the EA generated during instruction fetch or load/store operation, and the SR[CID] field. xTLBWyMR registers hold a tag that is compared with the current virtual address generated by the CPU core. Together with the xTLBWyTR registers and match logic they form a core part of the xMMU.

include::{imagesdir}/wavedrom/edn/xtlbmr.edn[]

<<<

[[XTLBMR]]
.XTLBMR Field Descriptions
[%autowidth, float="center", align="center", cols="^,^", options="headers",]
|===
|V	|Valid +
0 TLB entry invalid +
1 TLB entry valid
|PL1	|Page Level 1 +
0 Page level is 2 +
1 Page level is 1
|CID	|Context ID +
0-15 TLB entry translates for CID
|LRU	|Last Recently used +
0-3 Index in LRU queue (lower the number, more recent access)
|VPN	|Virtual Page Number +
0-N Number of the virtual frame that must match EA
|===

The CID bits can be hardwired to zero if the implementation does not support fast context switching and SR[CID] bits.

==== Data Translation Lookaside Buffer Way y Translate Registers(DTLBWyTR0-DTLBWyTR127)

The DTLBWyTR registers are 32-bit special-purpose supervisor-level registers accessible with the l.mtspr/l.mfspr instructions in supervisor mode.

Together with the DTLBWyMR registers they cache translation entries used for translating virtual to physical address. A virtual address is formed from the EA generated during a load/store operation, and the SR[CID] field. Together with the DTLBWyMR registers and match logic they form a core of the DMMU.

include::{imagesdir}/wavedrom/edn/dtlbtr.edn[]

[[DTLBTR]]
.DTLBTR Field Descriptions
[%autowidth, float="center", align="center", cols="^,^", options="headers",]
|===
|CC	|Cache Coherency +
0 Data cache coherency is not enforced for this page +
1 Data cache coherency is enforced for this page
|CI	|Cache Inhibit +
0 Cache is enabled for this page +
1 Cache is disabled for this page
|WBC	|Write-Back Cache +
0 Data cache uses write-through strategy for data from this page +
1 Data cache uses write-back strategy for data from this page
|WOM	|Weakly-Ordered Memory +
0 Strongly-ordered memory model for this page +
1 Weakly-ordered memory model for this page
|A	|Accessed +
0 Page was not accessed
1 Page was accessed
|D	|Dirty +
0 Page was not modified +
1 Page was modified
|URE	|User Read Enable x +
0 Load operation in user mode not permitted +
1 Load operation in user mode permitted
|UWE	|User Write Enable x +
0 Store operation in user mode not permitted +
1 Store operation in user mode permitted
|SRE	|Supervisor Read Enable x +
0 Load operation in supervisor mode not permitted +
1 Load operation in supervisor mode permitted
|SWE	|Supervisor Write Enable x +
0 Store operation in supervisor mode not permitted +
1 Store operation in supervisor mode permitted
|PPN	|Physical Page Number
0-N Number of the physical frame in memory
|===

==== Instruction Translation Lookaside Buffer Way y Translate Registers(ITLBWyTR0-ITLBWyTR127)

The ITLBWyTR registers are 32-bit special-purpose supervisor-level registers accessible with the l.mtspr/l.mfspr instructions in supervisor mode. 

Together with the ITLBWyMR registers they cache translation entries used for translating virtual to physical address. A virtual address is formed from the EA generated during an instruction fetch operation, and the SR[CID] field. Together with the ITLBWyMR registers and match logic they form a core part of the IMMU.

include::{imagesdir}/wavedrom/edn/itlbtr.edn[]

[[ITLBTR]]
.ITLBTR Field Description
[%autowidth, float="center", align="center", cols="^,^", options="headers",]
|===
|CC	|Cache Coherency +
0 Data cache coherency is not enforced for this page +
1 Data cache coherency is enforced for this page
|CI	|Cache Inhibit +
0 Cache is enabled for this page +
1 Cache is disabled for this page
|WBC	|Write-Back Cache +
0 Data cache uses write-through strategy for data from this page +
1 Data cache uses write-back strategy for data from this page
|WOM	|Weakly-Ordered Memory +
0 Strongly-ordered memory model for this page +
1 Weakly-ordered memory model for this page
|A	|Accessed +
0 Page was not accessed +
1 Page was accessed
|D	|Dirty +
0 Page was not modified +
1 Page was modified
|SXE	|Supervisor Execute Enable x +
0 Instruction fetch operation in supervisor mode not permitted +
1 Instruction fetch operation in supervisor mode permitted
|UXE	|User Execute Enable x +
0 Instruction fetch operation in user mode not permitted +
1 Instruction fetch operation in user mode permitted
|PPN	|Physical Page Number +
0-N Number of the physical frame in memory
|===

==== Instruction/Data Area Translation Buffer Match Registers (xATBMR0-xATBMR3)

The xATBMR registers are 32-bit special-purpose supervisor-level registers accessible with the l.mtspr/l.mfspr instructions in supervisor mode.

Together with the xATBTR registers they cache translation entries used for translating virtual to physical address of large address space areas. A virtual address is formed from the EA generated during an instruction fetch or load/store operation, and the SR[CID] field. xATBMR registers hold a tag that is compared with the current virtual address generated by the CPU core. Together with the xATBTR registers and match logic they form a core part of the xMMU.

include::{imagesdir}/wavedrom/edn/xatbmr.edn[]

[[xATBMR]]
.xATBMR Field Description
[%autowidth, float="center", align="center", cols="^,^", options="headers",]
|===
|V	|Valid +
0 TLB entry invalid +
1 TLB entry valid
|CID	|Context ID +
0-15 TLB entry translates for CID
|PS	|Page Size +
0 16 Mbyte page +
1 32 Gbyte page
|VPN	|Virtual Page Number +
0-N Number of the virtual frame that must match EA
|===

The CID bits can be hardwired to zero if the implementation does not support fast context switching and SR[CID] bits.

<<<

==== Data Area Translation Buffer Translate Registers (DATBTR0-DATBTR3)

The DATBTR registers are 32-bit special-purpose supervisor-level registers accessible with the l.mtspr/l.mfspr instructions in supervisor mode.

Together with the DATBMR registers they cache translation entries used for translating virtual to physical address. A virtual address is formed from the EA generated during a load/store operation, and the SR[CID] field. Together with the DATBMR registers and match logic they form a core part of the DMMU.

include::{imagesdir}/wavedrom/edn/datbmr.edn[]

[[DATBMR]]
.DATBMR Field Description
[%autowidth, float="center", align="center", cols="^,^", options="headers",]
|===
|CC	|Cache Coherency +
0 Data cache coherency is not enforced for this page +
1 Data cache coherency is enforced for this page
|CI	|Cache Inhibit +
0 Cache is enabled for this page +
1 Cache is disabled for this page
|WBC	|Write-Back Cache +
0 Data cache uses write-through strategy for data from this page +
1 Data cache uses write-back strategy for data from this page
|WOM	|Weakly-Ordered Memory +
0 Strongly-ordered memory model for this page +
1 Weakly-ordered memory model for this page
|A	|Accessed +
0 Page was not accessed +
1 Page was accessed
|D	|Dirty +
0 Page was not modified +
1 Page was modified
|SRE	|Supervisor Read Enable x +
0 Load operation in supervisor mode not permitted +
1 Load operation in supervisor mode permitted
|SWE	|Supervisor Write Enable x +
0 Store operation in supervisor mode not permitted +
1 Store operation in supervisor mode permitted
|URE	|User Read Enable x +
0 Load operation in user mode not permitted +
1 Load operation in user mode permitted
|UWE	|User Write Enable x +
0 Store operation in user mode not permitted +
1 Store operation in user mode permitted
|PPN	|Physical Page Number +
0-N Number of the physical frame in memory
|===

<<<

==== Instruction Area Translation Buffer Translate Registers (IATBTR0-IATBTR3)

The IATBTR registers are 32-bit special-purpose supervisor-level registers accessible with the l.mtspr/l.mfspr instructions in supervisor mode. 

Together with the IATBMR registers they cache translation entries used for translating virtual to physical address. A virtual address is formed from the EA generated during an instruction fetch operation, and the SR[CID] field. Together with the IATBMR registers and match logic they form a core part of the IMMU.

include::{imagesdir}/wavedrom/edn/iatbmr.edn[]

[[IATBMR]]
.IATBMR Field Description
[%autowidth, float="center", align="center", cols="^,^", options="headers",]
|===
|CC	|Cache Coherency +
0 Data cache coherency is not enforced for this page +
1 Data cache coherency is enforced for this page
|CI	|Cache Inhibit +
0 Cache is enabled for this page +
1 Cache is disabled for this page
|WBC	|Write-Back Cache +
0 Data cache uses write-through strategy for data from this page +
1 Data cache uses write-back strategy for data from this page
|WOM	|Weakly-Ordered Memory +
0 Strongly-ordered memory model for this page +
1 Weakly-ordered memory model for this page
|A	|Accessed +
0 Page was not accessed +
1 Page was accessed
|D	|Dirty +
0 Page was not modified +
1 Page was modified
|SXE	|Supervisor Execute Enable x +
0 Instruction fetch operation in supervisor mode not permitted +
1 Instruction fetch operation in supervisor mode permitted
|UXE	|User Execute Enable x +
0 Instruction fetch operation in user mode not permitted +
1 Instruction fetch operation in user mode permitted
|PPN	|Physical Page Number +
0-N Number of the physical frame in memory
|===

=== Address Translation Mechanism in 32-bit Implementations

Memory in an OpenRISC 1000 implementation with 32-bit effective addresses (EA) is divided into level 1 and level 2 pages. Translation is therefore based on two-level page table. However for virtual memory areas that do not need the smallest 8KB page granularity, only one level can be used.

.Memory Divided Into L1 and L2 pages
image::{imagesdir}/png/figure8-2.png[width=480, align="center"]

The first step in page address translation is to append the current SR[CID] bits as most significant bits to the 32-bit effective address, combining them into a 36-bit virtual address. This virtual address is then used to locate the correct page table entry (PTE) in the page tables in the memory. The physical page number is then extracted from the PTE and used in the physical address. Note that for increased performance, most processors implement on-chip translation lookaside buffers (TLBs) to cache copies of the recently-used PTEs.

.Address Translation Mechanism using Two-Level Page Table
image::{imagesdir}/png/figure8-3.png[width=480, align="center"]

Figure 8-3 shows an overview of the two-level page table translation of a virtual address to a physical address:

* Bits 35..32 of the virtual address select the page tables for the current context (process)
* Bits 31..24 of the virtual address correspond to the level 1 page number within the current context’s virtual space. The L1 page index is used to index the L1 page directory and to retrieve the PTE from it, or together with the L2 page index to match for the PTE in on-chip TLBs.
* Bits 23..13 of the virtual address correspond to the level 2 page number within the current context’s virtual space. The L2 page index is used to index the L2 page table and to retrieve the PTE from it, or together with the L1 page index to match for the PTE in on-chip TLBs.
* Bits 12..0 of the virtual address are the byte offset within the page; these are concatenated with the PPN field of the PTE to form the physical address used to access memory

The OpenRISC 1000 two-level page table translation also allows implementation of segments with only one level of translation. This greatly reduces memory requirements for the page tables since large areas of unused virtual address space can be covered only by level 1 PTEs.

.Address Translation Mechanism using Only L1 Page Type
image::{imagesdir}/png/figure8-4.png[]

Figure 8-4 shows an overview of the one-level page table translation of a virtual address to physical address:

* Bits 35..32 of the virtual address select the page tables for the current context (process)
* Bits 31..24 of the virtual address correspond to the level 1 page number within the current context’s virtual space. The L1 page index is used to index the L1 page table and to retrieve the PTE from it, or to match for the PTE in on-chip TLBs.
* Bits 23..0 of the virtual address are the byte offset within the page; these are concatenated with the truncated PPN field of the PTE to form the physical address used to access memory

=== Address Translation Mechanism in 64-bit Implementations

Memory in OpenRISC 1000 implementations with 64-bit effective addresses (EA) is divided into level 0, level 1 and level 2 pages. Translation is therefore based on three-level page table. However for virtual memory areas that do not need the smallest page granularity of 8KB, two level translation can be used.

.Memory Divided Into L0, L1 and L2 Pages
image::{imagesdir}/png/figure8-5.png[]

The first step in page address translation is truncation of the 64-bit effective address into a 46-bit address. Then the current SR[CID] bits are appended as most significant bits. The 50-bit virtual address thus formed is then used to locate the correct page table entry (PTE) in the page tables in the memory. The physical page number is then extracted from the PTE and used in the physical address. Note that for increased performance, most processors implement on-chip translation lookaside buffers (TLBs) to cache copies of the recently-used PTEs.

.Address Translation Mechanism using Three-Level Page Table
image::{imagesdir}/png/figure8-6.png[]

Figure 8-6 shows an overview of the three-level page table translation of a virtual address to physical address:

* Bits 49..46 of the virtual address select the page tables for the current context (process)
* Bits 45..35 of the virtual address correspond to the level 0 page number within current context's virtual space. The L0 page index is used to index the L0 page directory and to retrieve the PTE from it, or together with the L1 and L2 page indexes to match for the PTE in on-chip TLBs.
* Bits 34..24 of the virtual address correspond to the level 1 page number within the current context's virtual space. The L1 page index is used to index the L1 page directory and to retrieve the PTE from it, or together with the L0 and L2 page indexes to match for the PTE in on-chip TLBs.
* Bits 23..13 of the virtual address correspond to the level 2 page number within the current context's virtual space. The L2 page index is used to index the L2 page table and to retrieve the PTE from it, or together with the L0 and L1 page indexes to match for the PTE in on-chip TLBs.
* Bits 12..0 of the virtual address are the byte offset within the page; these are concatenated with the truncated PPN field of the PTE to form the physical address used to access memory

The OpenRISC 1000 three-level page table translation also allows implementation of large segments with two levels of translation. This greatly reduces memory requirements for the page tables since large areas of unused virtual address space can be covered only by level 1 PTEs.

.Address Translation Mechanism using Two-Level Page Table
image::{imagesdir}/png/figure8-7.png[]

Figure 8-7 shows an overview of the two-level page table translation of a virtual address to physical address:

* Bits 49..46 of the virtual address select the page tables for the current context (process)
* Bits 45..35 of the virtual address correspond to the level 0 page number within the current context’s virtual space. The L0 page index is used to index the L0 page directory and to retrieve the PTE from it, or together with the L1 page index to match for the PTE in on-chip TLBs.
* Bits 34..24 of the virtual address correspond to the level 1 page number within the current context’s virtual space. The L1 page index is used to index the L1 page table and to retrieve the PTE from it, or together with the L0 page index to match for the PTE in on-chip TLBs.
* Bits 23..0 of the virtual address are the byte offset within the page; these are concatenated with the truncated PPN field of the PTE to form the physical address used to access memory

=== Memory Protection Mechanism

After a virtual address is determined to be within a page covered by the valid PTE, the access is validated by the memory protection mechanism. If this protection mechanism prohibits the access, a page fault exception is generated.

The memory protection mechanism allows selectively granting read access, write access or execute access for both supervisor and user modes. The page protection mechanism provides protection at all page level granularities.

[[ProtectionAttributes]]
.Protection Attributes
[%autowidth, float="center", align="center", cols="^,^", options="headers",]
|===
|*Protection attribute*	|*Meaning*
|DMMUPR[SREx]	|Enable load operations in supervisor mode to the page.
|DMMUPR[SWEx]	|Enable store operations in supervisor mode to the page.
|IMMUPR[SXEx]	|Enable execution in supervisor mode of the page.
|DMMUPR[UREx]	|Enable load operations in user mode to the page.
|DMMUPR[UWEx]	|Enable store operations in user mode to the page.
|IMMUPR[UXEx]	|Enable execution in user mode of the page.
|===

Table 8-14 lists page protection attributes defined in MMU protection registers. For the individual page the appropriate strategy out of seven possible strategies programmed in MMU protection registers is selected with the PPI field of the PTE.

In OpenRISC 1000 processors that do not implement TLB/ATB reload in hardware, protection registers are not needed.

.Selection of Page Protection Attributes for Data Accesses
image::{imagesdir}/png/figure8-8.png[width=320, align="center"]

.Selection of Page Protection Attributes for Instruction Fetch Accesses
image::{imagesdir}/png/figure8-9.png[width=320, align="center"]

=== Page Table Entry Definition

Page table entries (PTEs) are generated and placed in page tables in memory by the operating system. A PTE is 32 bits wide and is the same for 32-bit and 64-bit OpenRISC 1000 processor implementations.

A PTE translates a virtual memory area into a physical memory area. How much virtual memory is translated depends on which level the PTE resides. PTEs are either in page directories with L bit zeroed or in page tables with L bit set. PTEs in page directories point to next level page directory or to final page table that containts PTEs for actual address translation.

include::{imagesdir}/wavedrom/edn/pte.edn[]

[[PTE]]
.PTE Field Description
[%autowidth, float="center", align="center", cols="^,^", options="headers",]
|===
|CC	|Cache Coherency +
0 Data cache coherency is not enforced for this page +
1 Data cache coherency is enforced for this page
|CI	|Cache Inhibit +
0 Cache is enabled for this page +
1 Cache is disabled for this page
|WBC	|Write-Back Cache +
0 Data cache uses write-through strategy for data from this page +
1 Data cache uses write-back strategy for data from this page
|WOM	|Weakly-Ordered Memory +
0 Strongly-ordered memory model for this page +
1 Weakly-ordered memory model for this page
|A	|Accessed +
0 Page was not accessed +
1 Page was accessed
|D	|Dirty +
0 Page was not modified +
1 Page was modified
|PPI	|Page Protection Index +
0 PTE is invalid +
1-7 Selects a group of six bits from a set of seven protection attribute groups in xMMUCR
|L	|Last +
0 PTE from page directory pointing to next page directory/table +
1 Last PTE in a linked form of PTEs (describing the actual page)
|PPN	|Physical Page Number +
0-N Number of the physical frame in memory
|===

=== Page Table Search Operation

An implementation may choose to implement the page table search operation in either hardware or software. For all page table search operations data addresses are untranslated (i.e. the effective and physical base address of the page table are the same).

When implemented in software, two TLB miss exceptions are used to handle TLB reload operations. Also, the software is responsible for maintaining accessed and dirty bits in the page tables.

=== Page History Recording

The accessed (A) and dirty (D) bits reside in each PTE and keep information about the history of the page. The operating system uses this information to determine which areas of the main memory to swap to the disk and which areas of the memory to load back to the main memory (demand-paging).

The accessed (A) bit resides both in the PTE in page table and in the copy of PTE in the TLB. Each time the page is accessed by a load, store or instruction fetch operation, the accessed bit is set.

If the TLB reload is performed in software, then the software must also write back the accessed bit from the TLB to the page table.

In cases when access operation to the page fails, it is not defined whether the accessed bit should be set or not. Since the accessed bit is merely a hint to the operating system, it is up to the implementation to decide.
It is up to the operating system to determine when to explicitly clear the accessed bit for a given page.

The dirty (D) bit resides in both the PTE in page table and in the copy of PTE in the TLB. Each time the page is modified by a store operation, the dirty bit is set.
If TLB reload is performed in software, then the software must also write back the dirty bit from the TLB to the page table.

In cases when access operation to the page fails, it is not defined whether the dirty bit should be set or not. Since the dirty bit is merely a hint to the operating system, it is up to the implementation to decide. However implementation or TLB reload software must check whether page is actually writable before setting the dirty bit.

It is up to the operating system to determine when to explicitly clear the dirty bit for a given page.

=== Page Table Updates

Updates to the page tables include operations like adding a PTE, deleting a PTE and modifying a PTE. On multiprocessor systems exclusive access to the page table must be assured before it is modified.

TLBs are noncoherent caches of the page tables and must be maintained accordingly. Explicit software synchronization between TLB and page tables is required so that page tables and TLBs remain coherent.

Since the processor reloads PTEs even during updates of the page table, special care must be taken when updating page tables so that the processor does not accidently use half modified page table entries.
